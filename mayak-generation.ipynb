{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Load a pretrained model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\nmodel","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-07T17:13:20.865253Z","iopub.execute_input":"2023-04-07T17:13:20.866205Z","iopub.status.idle":"2023-04-07T17:13:27.737796Z","shell.execute_reply.started":"2023-04-07T17:13:20.866167Z","shell.execute_reply":"2023-04-07T17:13:27.736722Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50264, 768)\n    (wpe): Embedding(2048, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50264, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"model.generation_config","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:13:27.739823Z","iopub.execute_input":"2023-04-07T17:13:27.740120Z","iopub.status.idle":"2023-04-07T17:13:27.748210Z","shell.execute_reply.started":"2023-04-07T17:13:27.740088Z","shell.execute_reply":"2023-04-07T17:13:27.747187Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"GenerationConfig {\n  \"_from_model_config\": true,\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Inference (two variants)","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nprompt = 'Ну привет'\ngenerator = pipeline(\"text-generation\", model=\"sberbank-ai/rugpt3small_based_on_gpt2\")\nres = generator(prompt, max_new_tokens=50)\nprint(res[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:13:27.749791Z","iopub.execute_input":"2023-04-07T17:13:27.750568Z","iopub.status.idle":"2023-04-07T17:13:33.859079Z","shell.execute_reply.started":"2023-04-07T17:13:27.750521Z","shell.execute_reply":"2023-04-07T17:13:33.857856Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Ну привет, — сказал он. — Я тут подумал, что ты, наверное, не знаешь, что я здесь.\n\n— Я знаю, — сказала я. — Я знаю, что ты здесь.\n\n— Я\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\ninputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\ninputs","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:13:33.862098Z","iopub.execute_input":"2023-04-07T17:13:33.862908Z","iopub.status.idle":"2023-04-07T17:13:34.912847Z","shell.execute_reply.started":"2023-04-07T17:13:33.862861Z","shell.execute_reply":"2023-04-07T17:13:34.911785Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"tensor([[7448, 6129]])"},"metadata":{}}]},{"cell_type":"code","source":"outputs = model.generate(inputs, max_new_tokens=100, do_sample=True, top_k=5, top_p=0.95)\ntokenizer.batch_decode(outputs, skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:13:34.914276Z","iopub.execute_input":"2023-04-07T17:13:34.914743Z","iopub.status.idle":"2023-04-07T17:13:40.093204Z","shell.execute_reply.started":"2023-04-07T17:13:34.914704Z","shell.execute_reply":"2023-04-07T17:13:40.092186Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['Ну привет!\\n\\n—\\xa0Привет!\\xa0— отозвался я, с любопытством глядя на девушку.\\xa0— А я вот, кажется, узнал тебя.\\n\\n—\\xa0Да, это я,\\xa0— ответила она, и я сразу понял, что это не она.\\n\\n—\\xa0А я,\\xa0— кивнул я.\\xa0— Меня зовут Сергей.\\n\\n—\\xa0А меня — Катя.\\n\\n—\\xa0Очень приятно,\\xa0— улыбнулся я.\\xa0— Меня зовут Сергей.\\n\\n']"},"metadata":{}}]},{"cell_type":"markdown","source":"## Dataset Preparation","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv('/kaggle/input/mayakovsky/Mayakovsky.txt', delimiter='|', names=['text'])\ndata","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:13:40.094881Z","iopub.execute_input":"2023-04-07T17:13:40.095277Z","iopub.status.idle":"2023-04-07T17:13:40.131783Z","shell.execute_reply.started":"2023-04-07T17:13:40.095238Z","shell.execute_reply":"2023-04-07T17:13:40.130786Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                   text\n0                                             КО ВСЕМУ \n1     Нет. Это неправда. Нет! И ты? Любимая, за что,...\n2     ложек! Белый, сшатался с пятого этажа. Ветер щ...\n3     Вознес над суетой столичной одури строгое древ...\n4     В грубом убийстве не пачкала рук ты. Ты уронил...\n...                                                 ...\n9833                                       поэтических \n9834                          рвачей и выжиг я подыму, \n9835       как большевистский партбилет, все сто томов \n9836                                              моих \n9837                                  партийных книжек.\n\n[9838 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>КО ВСЕМУ</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Нет. Это неправда. Нет! И ты? Любимая, за что,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ложек! Белый, сшатался с пятого этажа. Ветер щ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Вознес над суетой столичной одури строгое древ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>В грубом убийстве не пачкала рук ты. Ты уронил...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9833</th>\n      <td>поэтических</td>\n    </tr>\n    <tr>\n      <th>9834</th>\n      <td>рвачей и выжиг я подыму,</td>\n    </tr>\n    <tr>\n      <th>9835</th>\n      <td>как большевистский партбилет, все сто томов</td>\n    </tr>\n    <tr>\n      <th>9836</th>\n      <td>моих</td>\n    </tr>\n    <tr>\n      <th>9837</th>\n      <td>партийных книжек.</td>\n    </tr>\n  </tbody>\n</table>\n<p>9838 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = data.sample(frac=1.0)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:13:40.133220Z","iopub.execute_input":"2023-04-07T17:13:40.135359Z","iopub.status.idle":"2023-04-07T17:13:40.147501Z","shell.execute_reply.started":"2023-04-07T17:13:40.135322Z","shell.execute_reply":"2023-04-07T17:13:40.146492Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                   text\n887                          Я подымаю рельсовый бунт. \n1723                                       как знанье, \n6513                    такие же названия, как любимым \n1241                                    Если в будущее \n6280                                         а пишущий \n...                                                 ...\n255   Чтоб бешеной пляской землю овить, скучную, как...\n9302                           редактор. Стал вынослив \n28                                         Грудой дел, \n3425  от жары балда. Кто над морем не философствовал...\n6509              не в колокол названивая, не словами, \n\n[9838 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>887</th>\n      <td>Я подымаю рельсовый бунт.</td>\n    </tr>\n    <tr>\n      <th>1723</th>\n      <td>как знанье,</td>\n    </tr>\n    <tr>\n      <th>6513</th>\n      <td>такие же названия, как любимым</td>\n    </tr>\n    <tr>\n      <th>1241</th>\n      <td>Если в будущее</td>\n    </tr>\n    <tr>\n      <th>6280</th>\n      <td>а пишущий</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>255</th>\n      <td>Чтоб бешеной пляской землю овить, скучную, как...</td>\n    </tr>\n    <tr>\n      <th>9302</th>\n      <td>редактор. Стал вынослив</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Грудой дел,</td>\n    </tr>\n    <tr>\n      <th>3425</th>\n      <td>от жары балда. Кто над морем не философствовал...</td>\n    </tr>\n    <tr>\n      <th>6509</th>\n      <td>не в колокол названивая, не словами,</td>\n    </tr>\n  </tbody>\n</table>\n<p>9838 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\nnp.sum(data.isnull())","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:13:40.149210Z","iopub.execute_input":"2023-04-07T17:13:40.149561Z","iopub.status.idle":"2023-04-07T17:13:40.157817Z","shell.execute_reply.started":"2023-04-07T17:13:40.149525Z","shell.execute_reply":"2023-04-07T17:13:40.156862Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"text    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"bad_lines = data.loc[data.text.str.match('\\d{4}')]\nprint(np.unique(bad_lines.values))\nprint(bad_lines.size)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:13:40.159374Z","iopub.execute_input":"2023-04-07T17:13:40.160065Z","iopub.status.idle":"2023-04-07T17:13:40.181464Z","shell.execute_reply.started":"2023-04-07T17:13:40.160016Z","shell.execute_reply":"2023-04-07T17:13:40.180358Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"['1912 ' '1913 ' '1914 ' '1915 ' '1916 ' '1917 ' '1917 - 1926 ' '1918 '\n '1919 ' '1919, октябрь ' '1920 ' '1920 - 1921 ' '1920, август '\n '1920, июль ' '1921 ' '1921, январь ' '1922 ' '1922 - 1923 ' '1923 '\n '1924 ' '1925 ' '1926 ' '1926 Ялта, Симферополь, Гурзуф, Алупка ' '1927'\n '1927 ' '1929 ' '1930 ']\n183\n","output_type":"stream"}]},{"cell_type":"code","source":"clean_data = data.drop(bad_lines.index)\nclean_data","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:13:40.185384Z","iopub.execute_input":"2023-04-07T17:13:40.186017Z","iopub.status.idle":"2023-04-07T17:13:40.198297Z","shell.execute_reply.started":"2023-04-07T17:13:40.185914Z","shell.execute_reply":"2023-04-07T17:13:40.197261Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                   text\n887                          Я подымаю рельсовый бунт. \n1723                                       как знанье, \n6513                    такие же названия, как любимым \n1241                                    Если в будущее \n6280                                         а пишущий \n...                                                 ...\n255   Чтоб бешеной пляской землю овить, скучную, как...\n9302                           редактор. Стал вынослив \n28                                         Грудой дел, \n3425  от жары балда. Кто над морем не философствовал...\n6509              не в колокол названивая, не словами, \n\n[9655 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>887</th>\n      <td>Я подымаю рельсовый бунт.</td>\n    </tr>\n    <tr>\n      <th>1723</th>\n      <td>как знанье,</td>\n    </tr>\n    <tr>\n      <th>6513</th>\n      <td>такие же названия, как любимым</td>\n    </tr>\n    <tr>\n      <th>1241</th>\n      <td>Если в будущее</td>\n    </tr>\n    <tr>\n      <th>6280</th>\n      <td>а пишущий</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>255</th>\n      <td>Чтоб бешеной пляской землю овить, скучную, как...</td>\n    </tr>\n    <tr>\n      <th>9302</th>\n      <td>редактор. Стал вынослив</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Грудой дел,</td>\n    </tr>\n    <tr>\n      <th>3425</th>\n      <td>от жары балда. Кто над морем не философствовал...</td>\n    </tr>\n    <tr>\n      <th>6509</th>\n      <td>не в колокол названивая, не словами,</td>\n    </tr>\n  </tbody>\n</table>\n<p>9655 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"clean_data = clean_data.reset_index(drop=True)\nclean_data","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:13:40.199929Z","iopub.execute_input":"2023-04-07T17:13:40.200276Z","iopub.status.idle":"2023-04-07T17:13:40.212131Z","shell.execute_reply.started":"2023-04-07T17:13:40.200241Z","shell.execute_reply":"2023-04-07T17:13:40.211073Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                   text\n0                            Я подымаю рельсовый бунт. \n1                                          как знанье, \n2                       такие же названия, как любимым \n3                                       Если в будущее \n4                                            а пишущий \n...                                                 ...\n9650  Чтоб бешеной пляской землю овить, скучную, как...\n9651                           редактор. Стал вынослив \n9652                                       Грудой дел, \n9653  от жары балда. Кто над морем не философствовал...\n9654              не в колокол названивая, не словами, \n\n[9655 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Я подымаю рельсовый бунт.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>как знанье,</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>такие же названия, как любимым</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Если в будущее</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>а пишущий</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9650</th>\n      <td>Чтоб бешеной пляской землю овить, скучную, как...</td>\n    </tr>\n    <tr>\n      <th>9651</th>\n      <td>редактор. Стал вынослив</td>\n    </tr>\n    <tr>\n      <th>9652</th>\n      <td>Грудой дел,</td>\n    </tr>\n    <tr>\n      <th>9653</th>\n      <td>от жары балда. Кто над морем не философствовал...</td>\n    </tr>\n    <tr>\n      <th>9654</th>\n      <td>не в колокол названивая, не словами,</td>\n    </tr>\n  </tbody>\n</table>\n<p>9655 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_size = 955\ntrain_size = clean_data.size - test_size\ntrain_texts = clean_data.text.values[:train_size]\ntest_texts = clean_data.text.values[-test_size:]\ntrain_texts[:5], test_texts[:5]","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:13:40.213518Z","iopub.execute_input":"2023-04-07T17:13:40.214161Z","iopub.status.idle":"2023-04-07T17:13:40.222361Z","shell.execute_reply.started":"2023-04-07T17:13:40.214125Z","shell.execute_reply":"2023-04-07T17:13:40.221210Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(array(['Я подымаю рельсовый бунт. ', 'как знанье, ',\n        'такие же названия, как любимым ', 'Если в будущее ', 'а пишущий '],\n       dtype=object),\n array(['Не смеют надеяться: с кольцом экватора ', 'сыплет ',\n        'очень к вам привыкли. Ну, давайте, ',\n        'не вспомнят ни зги. История ',\n        'нету этаких... Мы найдем себе другую в разызысканной жакетке.Припомадясь '],\n       dtype=object))"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\n\ndev_pcnt = 0.1\ndev_size = int(train_size * dev_pcnt)\ntrain_df = pd.DataFrame(\n    {\n        'text': train_texts[:-dev_size],\n    }\n)\ndev_df = pd.DataFrame(\n    {\n        'text': train_texts[-dev_size:],\n    }\n)\ntest_df = pd.DataFrame(\n    {\n        'text': test_texts,\n    }\n)\n\ndata = DatasetDict(\n    {\n        'train': Dataset.from_pandas(train_df.reset_index(drop=True)),\n        'dev': Dataset.from_pandas(dev_df.reset_index(drop=True)),\n        'test': Dataset.from_pandas(test_df.reset_index(drop=True)),\n    }\n)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:13:40.224044Z","iopub.execute_input":"2023-04-07T17:13:40.224719Z","iopub.status.idle":"2023-04-07T17:13:40.383867Z","shell.execute_reply.started":"2023-04-07T17:13:40.224629Z","shell.execute_reply":"2023-04-07T17:13:40.382803Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 7830\n    })\n    dev: Dataset({\n        features: ['text'],\n        num_rows: 870\n    })\n    test: Dataset({\n        features: ['text'],\n        num_rows: 955\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"MAX_LENGTH = 128\n\ndef preprocess(batch):\n    return tokenizer(batch['text'], padding=True, truncation=True, max_length=MAX_LENGTH)\n    \ndata_tokenized = data.map(\n    lambda row: tokenizer(row['text']), batched=True, remove_columns=['text']\n)\ndata_tokenized","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:29:56.533424Z","iopub.execute_input":"2023-04-07T17:29:56.534438Z","iopub.status.idle":"2023-04-07T17:29:56.977486Z","shell.execute_reply.started":"2023-04-07T17:29:56.534383Z","shell.execute_reply":"2023-04-07T17:29:56.976332Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bee539d59d6f454eb82b0c0e79314533"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23859dbebebe4de98efc40d3ae87e772"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd206eb1d4ae4c109ecd7cc9f0cc458d"}},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 7830\n    })\n    dev: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 870\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 955\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"import gc\n\nimport torch\nfrom transformers import DataCollatorForLanguageModeling, TrainingArguments, Trainer\n\ntokenizer.pad_token = tokenizer.eos_token\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\ntraining_args = TrainingArguments(\n    output_dir = 'mayak_model',\n    evaluation_strategy='epoch',\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    save_steps=25000,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n)\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=data_tokenized['train'],\n    eval_dataset=data_tokenized['dev'],\n    data_collator=data_collator,\n)\n\ngc.collect()\ntorch.cuda.empty_cache()\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:31:56.518779Z","iopub.execute_input":"2023-04-07T17:31:56.519710Z","iopub.status.idle":"2023-04-07T17:37:50.194060Z","shell.execute_reply.started":"2023-04-07T17:31:56.519660Z","shell.execute_reply":"2023-04-07T17:37:50.190258Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n***** Running training *****\n  Num examples = 7830\n  Num Epochs = 3\n  Instantaneous batch size per device = 4\n  Total train batch size (w. parallel, distributed & accumulation) = 4\n  Gradient Accumulation steps = 1\n  Total optimization steps = 5874\n  Number of trainable parameters = 125231616\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5874' max='5874' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5874/5874 05:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>4.802900</td>\n      <td>4.597870</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.823900</td>\n      <td>4.724614</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.375600</td>\n      <td>4.870719</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 870\n  Batch size = 4\n***** Running Evaluation *****\n  Num examples = 870\n  Batch size = 4\n***** Running Evaluation *****\n  Num examples = 870\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5874, training_loss=3.8203137884506937, metrics={'train_runtime': 353.1915, 'train_samples_per_second': 66.508, 'train_steps_per_second': 16.631, 'total_flos': 250149355776000.0, 'train_loss': 3.8203137884506937, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"import math\n\neval_results = trainer.evaluate()\nprint(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")\neval_results","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:37:59.978776Z","iopub.execute_input":"2023-04-07T17:37:59.979505Z","iopub.status.idle":"2023-04-07T17:38:02.337779Z","shell.execute_reply.started":"2023-04-07T17:37:59.979466Z","shell.execute_reply":"2023-04-07T17:38:02.336657Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 870\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='218' max='218' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [218/218 00:02]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Perplexity: 130.41\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 4.8707194328308105,\n 'eval_runtime': 2.3426,\n 'eval_samples_per_second': 371.388,\n 'eval_steps_per_second': 93.061,\n 'epoch': 3.0}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model('mayak_model')","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:40:51.110999Z","iopub.execute_input":"2023-04-07T17:40:51.112024Z","iopub.status.idle":"2023-04-07T17:40:51.989518Z","shell.execute_reply.started":"2023-04-07T17:40:51.111968Z","shell.execute_reply":"2023-04-07T17:40:51.988330Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Saving model checkpoint to mayak_model\nConfiguration saved in mayak_model/config.json\nConfiguration saved in mayak_model/generation_config.json\nModel weights saved in mayak_model/pytorch_model.bin\n","output_type":"stream"}]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\"mayak_model\")\ntokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:44:34.228599Z","iopub.execute_input":"2023-04-07T17:44:34.229275Z","iopub.status.idle":"2023-04-07T17:44:37.252255Z","shell.execute_reply.started":"2023-04-07T17:44:34.229238Z","shell.execute_reply":"2023-04-07T17:44:37.248925Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"loading configuration file mayak_model/config.json\nModel config GPT2Config {\n  \"_name_or_path\": \"mayak_model\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 50256,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 2048,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\nloading weights file mayak_model/pytorch_model.bin\nGenerate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nAll model checkpoint weights were used when initializing GPT2LMHeadModel.\n\nAll the weights of GPT2LMHeadModel were initialized from the model checkpoint at mayak_model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\nloading configuration file mayak_model/generation_config.json\nGenerate config GenerationConfig {\n  \"_from_model_config\": true,\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nCould not locate the tokenizer configuration file, will try to use the model config instead.\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/config.json\nModel config GPT2Config {\n  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 50256,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 2048,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\nloading file vocab.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/vocab.json\nloading file merges.txt from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/merges.txt\nloading file tokenizer.json from cache at None\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at None\nloading file tokenizer_config.json from cache at None\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/config.json\nModel config GPT2Config {\n  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 50256,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 2048,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/config.json\nModel config GPT2Config {\n  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 50256,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 50256,\n  \"gradient_checkpointing\": false,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 2048,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 2048,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = 'Ну привет'\ninputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\nfor _ in range(5):\n    outputs = model.generate(inputs, max_new_tokens=50, do_sample=True, top_k=3, top_p=0.95, repetition_penalty=1.5)\n    print(tokenizer.batch_decode(outputs, skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T18:01:12.963247Z","iopub.execute_input":"2023-04-07T18:01:12.964217Z","iopub.status.idle":"2023-04-07T18:01:26.480248Z","shell.execute_reply.started":"2023-04-07T18:01:12.964162Z","shell.execute_reply":"2023-04-07T18:01:26.479006Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ну приветствую, товарищ судья.  Ну что ж...  Я не против того чтоб в моем доме жили такие-то людишки и подобные им? Нет! Пусть живут себе на даче или под пальмой у моей любимой бабушки! И пусть едят мою любимую']\n","output_type":"stream"},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ну привет, ройсь! Я пришел к тебе. Не гневи бога ради: я не враг твой и даже рад тебя видеть... Но если ты думаешь меня прогнать из Кремля в полночь или день - иди вон отсюда с глаз долой!\" И скрылся']\n","output_type":"stream"},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ну привет, росиянская рать! Не думал я... Думал ли - нет. Я ж не из тех, кто любит громить и грабить богатых или просто устал от войн. Но вот грянула война: \"Иди!\" И сразу же']\n","output_type":"stream"},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ну приветствую!  - Доброе утро, мистер Форд. Рад вас видеть... Ну как вам? Как вы себя чувствуете?..  И сразу же:  - Я в очень плохом состоянии!..  В комнате стало тихо и пусто; кромешная тьма']\n['Ну приветствую вас, товарищи!  - Что ж...  Не очень приятно вам было с нами познакомиться. А теперь скажите: это вы были на съезде Советов?  Мы знаем кого мы выбирали вождем Советского Союза и кто был нашим кумиром в']\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = 'Ведь если звезды зажигают'\ninputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\nfor _ in range(5):\n    outputs = model.generate(inputs, max_new_tokens=50, do_sample=True, top_k=5, top_p=0.95)\n    print(tokenizer.batch_decode(outputs, skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:57:46.026365Z","iopub.execute_input":"2023-04-07T17:57:46.027003Z","iopub.status.idle":"2023-04-07T17:57:59.734332Z","shell.execute_reply.started":"2023-04-07T17:57:46.026964Z","shell.execute_reply":"2023-04-07T17:57:59.732903Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ведь если звезды зажигают, значит,  их  кто-то  гонит  из мрака.  - Кто это?!  -  не в силах  удержаться,  чтоб не заорать:  - Кто-то  гонит  из мрака']\n","output_type":"stream"},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ведь если звезды зажигают в глазах, то значит,  кто-то  в сердце  горит.  А если  на небе  -  сплошной  сплошной  сплошной  сплошной  сплошной  сплошной  сплошной  сплошной  сплошной  сплошной  сплошной  сплошной  сплошной']\n","output_type":"stream"},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ведь если звезды зажигают в сердце, значит,  они  - друзья.  И в жизни,  и в смерти  - мы  друзья,  и мы  в горе  - не друзья.  И в сердце  - наша сила.  И мы ']\n","output_type":"stream"},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ведь если звезды зажигают огни, то, может быть, оттого, что в небо, как в чашу, налита вода, то, может быть, оттого, что в небо налита вода, и, может быть, оттого, что в воду налита земля\". ']\n['Ведь если звезды зажигают,  то  чтоб  чтоб  в комнате  не было  скучно  тем,  кто  сидит  у окна  в своем кабинете.  А если  в окне  горит  лампочка,  то  чтоб  не  было']\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = 'Ведь если звезды зажигают'\ninputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\nfor _ in range(5):\n    outputs = model.generate(inputs, max_new_tokens=50, do_sample=True, top_k=5, top_p=0.95, repetition_penalty=1.5)\n    print(tokenizer.batch_decode(outputs, skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:58:09.135070Z","iopub.execute_input":"2023-04-07T17:58:09.136026Z","iopub.status.idle":"2023-04-07T17:58:22.365628Z","shell.execute_reply.started":"2023-04-07T17:58:09.135975Z","shell.execute_reply":"2023-04-07T17:58:22.364364Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ведь если звезды зажигают в глазах, то значит  это кто-то чужой. А я не враг вам и вашим звездам: мне они ближе по духу! - Простите великодушно,- сказал поэт,- а где вы были? Я бы на вашем месте тоже...  Но']\n","output_type":"stream"},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ведь если звезды зажигают,  то их же надо смотреть! А мы живем в постоянном страхе. Мы знаем: от пули можно уйти и живым; но нам страшно даже выйти из этого самого смерча... В мире все так-то просто - не бывает ничего простого или']\n","output_type":"stream"},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ведь если звезды зажигают,  чтоб в небо лезли люди и чтобы из земли вылезал скелет - это хорошо. Я знаю одного знаменитого ученого: он сидит на корточках возле столика с книжкой. Он пишет роман о голоде-беде... А когда ему скучно']\n","output_type":"stream"},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ведь если звезды зажигают их в угоду чьим-то капризам, то значит ли это что я один из них? Нет!  - Вы не правы,- сказал он наконец.  И опять же: нет... Не может быть!.. Он встал со стула и вышел']\n['Ведь если звезды зажигают, то их  огни - наши тени... Мы любим тебя. А они нас не любят! Неправда ли чудная вещь?!\" И так далее в том же роде\". В самом деле: \"А что это за книга?\" Ответил ей Петр']\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = 'Ведь если звезды зажигают'\ninputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\nfor _ in range(5):\n    outputs = model.generate(inputs, max_new_tokens=50, do_sample=True, top_k=3, top_p=0.95, repetition_penalty=1.5)\n    print(tokenizer.batch_decode(outputs, skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T18:00:20.572765Z","iopub.execute_input":"2023-04-07T18:00:20.573174Z","iopub.status.idle":"2023-04-07T18:00:34.309370Z","shell.execute_reply.started":"2023-04-07T18:00:20.573140Z","shell.execute_reply":"2023-04-07T18:00:34.308081Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ведь если звезды зажигают глаза, значит это не так уж страшно.  И вот они зажглись и засверкали ярче солнца...И сразу же за ними в небе вырос огромный черный дракон!  Он был очень велик: около трех метров длиной с лошадь; он тя']\n","output_type":"stream"},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ведь если звезды зажигают глаза, значит  в комнате что-то не так; и я вижу: это кто же там сидит на корточках? И вот из глаз у меня вытекла одна слеза. - Я знаю этого парня! Он живет с другими людьми... А']\n","output_type":"stream"},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ведь если звезды зажигают глаза, значит  они не для этого. Я знаю одного человека - он умер от голода и холода... Он жил в коммуне на берегу Днепра! Там же был убит голодным звоном зубовный скрежет!.. И вот сидит этот самый человек']\n","output_type":"stream"},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ведь если звезды зажигают глаза, значит  они тоже люди. И в комнате у них есть диван и столик для книг... Вот так-то! А что ж им - человеку?! Человеку ведь не нужно ничего кроме него самого: его тело; душу он любит больше всего']\n['Ведь если звезды зажигают в глазах, то это не от солнца. А кто их знает?  И вот однажды на небе вспыхнула яркая звезда и зажглась над миром... Венера!  Луна сияла долго-долго: - Я знаю эту ночь лучше других ночей']\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = 'Ну привет'\ninputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\noutputs = model.generate(inputs, max_new_tokens=50, do_sample=False)\nprint(tokenizer.batch_decode(outputs, skip_special_tokens=True))\nprompt = 'Ведь если звезды зажигают'\ninputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\noutputs = model.generate(inputs, max_new_tokens=50, do_sample=False)\nprint(tokenizer.batch_decode(outputs, skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T17:59:42.639185Z","iopub.execute_input":"2023-04-07T17:59:42.639555Z","iopub.status.idle":"2023-04-07T17:59:47.582466Z","shell.execute_reply.started":"2023-04-07T17:59:42.639521Z","shell.execute_reply":"2023-04-07T17:59:47.581249Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256,\n  \"transformers_version\": \"4.26.1\"\n}\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"['Ну приветствую вас, товарищи!  - Доброе утро, товарищ!  - Доброе утро, товарищ!  - Доброе утро, товарищ!  - Доброе утро, товарищ!  - Доброе утро, товарищ!  - Доброе утро']\n['Ведь если звезды зажигают,  то,  может быть,  чтоб их не было видно?  И если  в небе  горит  яркая звезда,  то  это  не звезда,  а просто  яркая  яркая  звезда.  И если  в']\n","output_type":"stream"}]}]}
